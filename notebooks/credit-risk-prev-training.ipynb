{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\nfrom imblearn.over_sampling import SMOTE\n\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.stats.mstats import mode, gmean, hmean\n\nimport os\nprint(os.listdir(\"../input\"))\n    \ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/home-credit-default-risk/application_train.csv', usecols=['SK_ID_CURR','TARGET'])\n#test = pd.read_csv('../input/application_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae901f52de81167c9c65637360161f66378cbdfb","collapsed":true},"cell_type":"code","source":"#prev = pd.read_csv('../input/home-credit-default-risk/previous_application.csv')\n#prev.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cad4c30fd32bad84c774853beab6feae1ab50b9e","collapsed":true},"cell_type":"code","source":"prev = pd.read_csv('../input/home-credit-default-risk/previous_application.csv')\nprev = prev.loc[prev['FLAG_LAST_APPL_PER_CONTRACT']=='Y'] #mistake rows\ndel prev['FLAG_LAST_APPL_PER_CONTRACT']\n\n#replace strange number of days as nan\nfor f_ in ['DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION']:\n    prev[f_].loc[prev[f_]>360000] = np.nan\n\n#create some features\nprev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\nprev['AMT_DIFF_CREAPP'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\nprev['AMT_DIFF_CREDIT_GOODS'] = prev['AMT_CREDIT'] - prev['AMT_GOODS_PRICE']\nprev['AMT_CREDIT_GOODS_PERC'] = prev['AMT_CREDIT'] / prev['AMT_GOODS_PRICE']\nprev['AMT_PAY_YEAR'] = prev['AMT_CREDIT'] / prev['AMT_ANNUITY']\nprev['DAYS_TOTAL'] = prev['DAYS_LAST_DUE'] - prev['DAYS_FIRST_DUE']\nprev['DAYS_TOTAL2'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_FIRST_DUE']\nprev['AMT_LEFT'] = (prev['AMT_CREDIT'] - prev['AMT_ANNUITY'] * prev['DAYS_LAST_DUE_1ST_VERSION']/365.25).clip(lower=0)\nprev['PAYMENT_LEFT'] = prev['AMT_LEFT']/prev['AMT_ANNUITY']\n\n#these features highly correlated with others or not useful?\nrejected_features = ['AMT_GOODS_PRICE',\n                     'WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START',\n                     'NFLAG_LAST_APPL_IN_DAY']\nfor f_ in rejected_features:\n    del prev[f_]\n    \n#Label Encoding\ncategorical_feats = [\n    f_ for f_ in prev.columns if prev[f_].dtype == 'object'\n]\n\nfor f_ in categorical_feats:\n    nunique = prev[f_].nunique(dropna=False)\n    print(f_,nunique,prev[f_].unique())\n    #if (nunique<5):\n    #    cat_feats.append('prev_'+f_)\n    #else:\n    #    meanenc_feats.append('prev_'+f_)\n    prev[f_], indexer = pd.factorize(prev[f_])\n    \nprev.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2df5c71c76f5bf2615bc30a3a3210bab9206d41e","collapsed":true},"cell_type":"code","source":"inst = pd.read_csv('../input/home-credit-default-risk/installments_payments.csv')\ninst_NUM_INSTALMENT_VERSION = inst.groupby(['SK_ID_PREV'])['NUM_INSTALMENT_VERSION'].nunique()\n\n#merge payments of same month\n#maybe helpful for: inst.loc[(inst.SK_ID_PREV==1000005) & (inst.SK_ID_CURR==176456) & (inst.NUM_INSTALMENT_NUMBER==9)]\ninst['DAYS_ENTRY_PAYMENT_weighted'] = inst['DAYS_ENTRY_PAYMENT'] * inst['AMT_PAYMENT']\ninst['MONTHS_BALANCE'] = (inst['DAYS_INSTALMENT']/30.4375).astype('int')\ninst = inst.groupby(['SK_ID_PREV','SK_ID_CURR','MONTHS_BALANCE']).agg({'DAYS_INSTALMENT':'mean',\n                                                                       'DAYS_ENTRY_PAYMENT_weighted':'sum',\n                                                                       'AMT_INSTALMENT':'mean',\n                                                                       'AMT_PAYMENT':'sum'})\ninst['DAYS_ENTRY_PAYMENT'] = inst['DAYS_ENTRY_PAYMENT_weighted']/inst['AMT_PAYMENT']\ninst = inst.reset_index()\ndel inst['DAYS_ENTRY_PAYMENT_weighted']\ninst.head()\n\ninst['AMT_PAYMENT_PERC'] = inst['AMT_PAYMENT'] / (1+inst['AMT_INSTALMENT'])\ninst['AMT_PAYMENT_DIFF'] = inst['AMT_PAYMENT'] - inst['AMT_INSTALMENT']\ninst['DPD'] = (inst['DAYS_ENTRY_PAYMENT'] - inst['DAYS_INSTALMENT']).clip(lower=0)\ninst['DBD'] = (inst['DAYS_INSTALMENT'] - inst['DAYS_ENTRY_PAYMENT']).clip(lower=0)\ninst['DPD'].fillna(30,inplace=True)\ninst['DBD'].fillna(0,inplace=True)\n\n#when is the last time late\ninst_last_late = inst[inst.DAYS_INSTALMENT < inst.DAYS_ENTRY_PAYMENT].groupby(['SK_ID_PREV'])['DAYS_INSTALMENT'].max()\ninst_last_late.rename('DAYS_LAST_LATE',inplace=True)\n\n#when is the last time underpaid\ninst_last_underpaid = inst[inst.AMT_INSTALMENT < inst.AMT_PAYMENT].groupby(['SK_ID_PREV'])['DAYS_INSTALMENT'].max()\ninst_last_underpaid.rename('DAYS_LAST_UNDERPAID',inplace=True)\n\nnum_aggregations = {\n    'MONTHS_BALANCE': ['size','min','max'],\n    'AMT_PAYMENT_PERC': ['max','mean','var'],\n    'AMT_PAYMENT_DIFF': [ 'sum', 'mean','var'],\n    'AMT_PAYMENT': [ 'sum','mean','var'],\n    'DPD': ['sum', 'max','mean','var'],\n    'DBD': ['sum', 'max','mean','var'],\n}\ninst = inst.groupby('SK_ID_PREV').agg(num_aggregations)\ninst.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in inst.columns.tolist()])\ninst['N_NUM_INSTALMENT_VERSION'] = inst_NUM_INSTALMENT_VERSION\ninst['DAYS_LAST_LATE'] = inst_last_late\ninst['DAYS_LAST_UNDERPAID'] = inst_last_underpaid\ninst_trend = pd.read_csv('../input/my-credit-risk/inst_fit.csv',index_col=0)\ninst_trend.index.name = 'SK_ID_PREV'\ninst = inst.merge(inst_trend, on='SK_ID_PREV', how='left')\ninst = inst.add_prefix('inst_')\ninst.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f531fcbea28a0f1f4232f7f4f2fbfd3e441edf8","collapsed":true},"cell_type":"code","source":"pos = pd.read_csv('../input/home-credit-default-risk/POS_CASH_balance.csv')\nidx = pos.groupby(['SK_ID_PREV'])['MONTHS_BALANCE'].idxmax() #most recent data\npos_recent = pos[['SK_ID_PREV','MONTHS_BALANCE','CNT_INSTALMENT','CNT_INSTALMENT_FUTURE',\n                  'NAME_CONTRACT_STATUS','SK_DPD','SK_DPD_DEF']].loc[idx.values]\npos_recent['NAME_CONTRACT_STATUS'],indexer = pd.factorize(pos_recent['NAME_CONTRACT_STATUS'])\npos_recent.set_index('SK_ID_PREV',inplace=True)\npos_recent.columns = ['pos_recent_' + f_ for f_ in pos_recent.columns]\n\n#what is the last month with DPD\npos_last_DPD = pos[pos.SK_DPD>0].groupby(['SK_ID_PREV'])['MONTHS_BALANCE'].max()\npos_last_DPD.rename('MONTH_LAST_DPD',inplace=True)\n\npos['has_DPD'] = 0\npos['has_DPD'].loc[pos['SK_DPD']>0] = 1\nnum_aggregations = {\n    'MONTHS_BALANCE': ['size'],\n    'has_DPD': ['sum','mean'],\n    'SK_DPD': ['max','mean'],\n    'SK_DPD_DEF': [ 'sum', 'median'],\n}\npos = pos.groupby('SK_ID_PREV').agg(num_aggregations)\npos.columns = pd.Index(['pos_' + e[0] + \"_\" + e[1].upper() for e in pos.columns.tolist()])\npos = pos.merge(pos_recent, how='outer', on='SK_ID_PREV')\n\npos_trend = pd.read_csv('../input/prev-pos-trend/pos_fit.csv',index_col=0)\npos_trend.index.name = 'SK_ID_PREV'\npos = pos.merge(pos_trend, how='outer', on='SK_ID_PREV')\n\npos['MONTH_LAST_DPD'] = pos_last_DPD\ndel pos_recent\ngc.collect\npos.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d01b5d820eefb3eb07cb1bbc273c9027a698b2dc","collapsed":true},"cell_type":"code","source":"ccbl = pd.read_csv('../input/home-credit-default-risk/credit_card_balance.csv')\nccbl['AMT_BALANCE_CREDIT_RATIO'] = (ccbl['AMT_BALANCE']/(ccbl['AMT_CREDIT_LIMIT_ACTUAL']+0.001)).clip(-100,100)\nccbl['AMT_CREDIT_USE_RATIO'] = (ccbl['AMT_DRAWINGS_CURRENT']/(ccbl['AMT_CREDIT_LIMIT_ACTUAL']+0.001)).clip(-100,100)\nccbl['AMT_DRAWING_ATM_RATIO'] = ccbl['AMT_DRAWINGS_ATM_CURRENT']/(ccbl['AMT_DRAWINGS_CURRENT']+0.001)\nccbl['AMT_PAY_USE_RATIO'] = ((ccbl['AMT_PAYMENT_TOTAL_CURRENT']+0.001)/(ccbl['AMT_DRAWINGS_CURRENT']+0.001)).clip(-100,100)\nccbl['AMT_BALANCE_RECIVABLE_RATIO'] = ccbl['AMT_BALANCE']/(ccbl['AMT_TOTAL_RECEIVABLE']+0.001)\nccbl['AMT_DRAWING_BALANCE_RATIO'] = ccbl['AMT_DRAWINGS_CURRENT']/(ccbl['AMT_BALANCE']+0.001)\nccbl['AMT_RECEIVABLE_PRINCIPAL_DIFF'] = ccbl['AMT_TOTAL_RECEIVABLE']-ccbl['AMT_RECEIVABLE_PRINCIPAL']\nccbl['AMT_PAY_INST_DIFF'] = ccbl['AMT_PAYMENT_CURRENT'] - ccbl['AMT_INST_MIN_REGULARITY']\n\nrejected_features = ['AMT_RECIVABLE','AMT_RECEIVABLE_PRINCIPAL',\n                     'AMT_DRAWINGS_POS_CURRENT']\nfor f_ in rejected_features:\n    del ccbl[f_]\n\nccbl_last_DPD = ccbl[ccbl.SK_DPD>0].groupby(['SK_ID_CURR'])['MONTHS_BALANCE'].max()\nccbl_last_DPD.rename('MONTH_LAST_DPD',inplace=True)\n\nsum_feats = [f_ for f_ in ccbl.columns.values[3:] if (f_.find('RATIO')==-1) & (f_.find('CNT')==-1)]\nprint ('sum_feats', sum_feats)\nccbl_sum =  ccbl.groupby('SK_ID_PREV')[sum_feats].sum()\nccbl_sum = ccbl_sum.add_prefix('sum_')\n\nmean_feats = [f_ for f_ in ccbl.columns.values[3:]]\nprint ('mean_feats', mean_feats)\nccbl_mean = ccbl.groupby('SK_ID_PREV')[mean_feats].mean()\nccbl_mean = ccbl_mean.add_prefix('mean_')\n\nccbl = ccbl_mean.merge(ccbl_sum, how='outer', on='SK_ID_PREV')\n\nccbl_trend = pd.read_csv('../input/prev-cc-trend/ccbl_fit.csv', index_col=0)\nccbl_trend.index.name = 'SK_ID_PREV'\n#for credit card balance we use slopes only for now...\nslopes = [f_ for f_ in ccbl_trend.columns.values if f_.find('_k')>=0]\nccbl_trend = ccbl_trend[slopes]\nccbl = ccbl.merge(ccbl_trend , how='outer', on='SK_ID_PREV')\n\nccbl['last_DPD'] = ccbl_last_DPD\nccbl = ccbl.add_prefix('cc_')\ndel ccbl_mean, ccbl_sum\ngc.collect()\nccbl.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baa65f969f4705f92b5d144b24e6e5bc4aff9cc0","collapsed":true},"cell_type":"code","source":"prev_meta = prev.merge(inst, on='SK_ID_PREV', how='left')\nprev_meta = prev_meta.merge(pos, on='SK_ID_PREV', how='left')\nprev_meta = prev_meta.merge(ccbl, on='SK_ID_PREV', how='left')\ndel inst, pos, ccbl\ngc.collect()\nprev_meta.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10ecbd9d5cfd7eab9c435eb5337f05f65e2af463","collapsed":true},"cell_type":"code","source":"interest_tmp = prev_meta['RATE_INTEREST_PRIVILEGED'].fillna(0)\ndownpayment_tmp = prev_meta['AMT_DOWN_PAYMENT'].fillna(0)\ninst_AMT_PAYMENT_SUM_tmp = prev_meta['inst_AMT_PAYMENT_SUM'].fillna(0)\nprev_meta['AMT_LEFT2'] = (prev_meta['AMT_CREDIT']-downpayment_tmp)*(1+interest_tmp) - inst_AMT_PAYMENT_SUM_tmp\nprev_meta['AMT_LEFT2'] = prev_meta['AMT_LEFT2'].clip(lower=0)\nprev_meta['AMT_LEFT2'].loc[prev_meta['NAME_CONTRACT_STATUS']!=0] = 0\nprev_meta['PAYMENT_CREDIT_RATIO'] = prev_meta['inst_AMT_PAYMENT_SUM']/prev_meta['AMT_CREDIT']\nprev_meta['AMT_LEFT3'] = prev_meta['AMT_CREDIT'] * prev_meta['pos_recent_CNT_INSTALMENT']/ (prev_meta['pos_recent_CNT_INSTALMENT_FUTURE'] + prev_meta['pos_recent_CNT_INSTALMENT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d109c5151936146a9c725c25d69261d1410f75e","collapsed":true},"cell_type":"code","source":"target_map = pd.Series(data.TARGET.values, index=data.SK_ID_CURR.values)\ny = prev_meta['SK_ID_CURR'].map(target_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"404c1dac11574526686d7600d65068d26da7ce52"},"cell_type":"code","source":"train_x = prev_meta.loc[~y.isnull()]\ntest_x = prev_meta.loc[y.isnull()]\ntrain_y = y.loc[~y.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43bfc82ca17e3f3fe79c683d8ba36d07497c1a0c","collapsed":true},"cell_type":"code","source":"excluded_feats = ['SK_ID_CURR','SK_ID_PREV']\nfeatures = [f_ for f_ in train_x.columns.values if not f_ in excluded_feats]\nprint(excluded_feats)\n\ntrain_x = prev_meta.loc[~y.isnull()]\ntest_x = prev_meta.loc[y.isnull()]\ntrain_y = y.loc[~y.isnull()]\n\n# Run a 5 fold\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\noof_preds = np.zeros(train_x.shape[0])\nsub_preds = np.zeros(test_x.shape[0])\nfeature_importance_df = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b177a74c9d45c1c8fb9f64e2dd4651cc948dced","collapsed":true},"cell_type":"code","source":"scores = []\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_x, train_y)):\n    trn_x, val_x = train_x[features].iloc[trn_idx], train_x[features].iloc[val_idx]\n    trn_y, val_y = train_y.iloc[trn_idx], train_y.iloc[val_idx]\n\n    #val_test = pd.concat([val,test],axis=0,sort=False)\n    #val_size = val.shape[0]\n    #test_size = test.shape[0]\n    #print ('doing mean_encoding')\n    #trn, val_test = mean_encode(trn, val_test, meanenc_feats, 'TARGET', drop=True)\n    #features = [f_ for f_ in trn.columns if f_ not in excluded_feats]\n    \n    #val  = val_test.iloc[0:val_size, :].copy(deep=True)\n    #test_x = val_test[features].iloc[-test_size:,:].copy(deep=True)\n        \n    #trn_x, trn_y = trn[features], trn['TARGET']\n    #val_x, val_y = val[features], val['TARGET']\n    \n    clf = LGBMClassifier(\n        n_estimators=5000,\n        learning_rate=0.05,\n        num_leaves=20,\n        colsample_bytree=0.3,\n        subsample=0.9,\n        max_depth=5,\n        reg_alpha=5,\n        reg_lambda=4,\n        min_split_gain=0.002,\n        min_child_weight=40,\n        silent=True,\n        verbose=-1,\n        n_jobs = 16,\n        random_state = n_fold * 619,\n        scale_pos_weight = 2\n    )\n    \n    clf.fit(trn_x, trn_y, \n            eval_set= [(val_x, val_y)], \n            eval_metric='auc', verbose=100, early_stopping_rounds=50,\n            categorical_feature = categorical_feats,\n           )\n    \n    oof_preds[val_idx] = clf.predict_proba(val_x)[:, 1]\n    sub_preds += clf.predict_proba(test_x[features])[:, 1] / folds.n_splits\n    \n    fold_score = roc_auc_score(val_y, oof_preds[val_idx])\n    scores.append(fold_score)\n    print('Fold %2d AUC : %.6f' % (n_fold + 1, fold_score))\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importances_\n    fold_importance_df[\"fold\"] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    del clf, trn_x, trn_y, val_x, val_y\n    gc.collect()\n    \nprint('Full AUC score %.6f +- %0.4f' % (roc_auc_score(train_y, oof_preds), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15ca65952b8a26f0ef3f277097b41a4a8910cb26","collapsed":true},"cell_type":"code","source":"train_prev_score = train_x[['SK_ID_CURR','SK_ID_PREV','DAYS_DECISION']]\ntrain_prev_score['score'] = oof_preds\ntest_prev_score = test_x[['SK_ID_CURR','SK_ID_PREV','DAYS_DECISION']]\ntest_prev_score['score'] = sub_preds\nprev_score = pd.concat([train_prev_score,test_prev_score])\nprev_score.to_csv('prev_score.csv',index=False,compression='zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da2e2d5b227be80c2d6fd3c0c8ac85c9a7bd5dd7","collapsed":true},"cell_type":"code","source":"agg_prev_score = prev_score.groupby('SK_ID_CURR')['score'].agg({'max','mean','sum','var'})\n\nagg_prev_score_recent2y = prev_score.loc[prev_score['DAYS_DECISION']>-365.25*2].groupby('SK_ID_CURR')['score'].sum()\n\nidx = prev_score.groupby(['SK_ID_CURR'])['DAYS_DECISION'].idxmax()\nagg_prev_score_last = prev_score[['SK_ID_CURR','score']].loc[idx.values]\nagg_prev_score_last.set_index('SK_ID_CURR',inplace=True)\n\nagg_prev_score['recent2y_sum'] = agg_prev_score_recent2y\nagg_prev_score['last'] = agg_prev_score_last\nagg_prev_score = agg_prev_score.add_prefix('prev_score_')\nagg_prev_score['TARGET'] = target_map\nagg_prev_score.to_csv('agg_prev_score.csv',compression='zip')\nagg_prev_score.groupby('TARGET').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5f89aa1185fff64fb19e8fef170ed42d7665306d"},"cell_type":"code","source":"for col in agg_prev_score.columns:\n    print(col,agg_prev_score[col].corr(agg_prev_score['TARGET']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"81ee93b4a7528b256fe51b2c6261240382f379a1"},"cell_type":"code","source":"# Plot feature importances\nfeature_importance = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n    by=\"importance\", ascending=False)\n#feature_importance['correlation'] = corr.loc[feature_importance.index.values]\nfeature_importance.to_csv('feature_importance.csv')\n\nbest_features = feature_importance.iloc[:50].reset_index()\n\nimport matplotlib.gridspec as gridspec\nfig = plt.figure(figsize=(8, 16))\ngs = gridspec.GridSpec(1, 1)\n# Plot Split importances\nax = plt.subplot(gs[0, 0])\nsns.barplot(x='importance', y='feature', data=best_features, ax=ax)\nax.set_title('Feature scores wrt split importances', fontweight='bold', fontsize=14)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}