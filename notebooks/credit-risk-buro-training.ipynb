{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bureau record training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv.zip', 'installments_payments.csv.zip', 'application_test.csv.zip', 'HomeCredit_columns_description.csv', 'previous_application.csv.zip', 'bureau_balance.csv.zip', 'POS_CASH_balance.csv.zip', 'credit_card_balance.csv.zip', 'application_train.csv.zip', 'bureau.csv.zip']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "    \n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/application_train.csv.zip', usecols=['SK_ID_CURR','TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create features for each bureau record. Apart from raw features from bureau table, we also compute:\n",
    "* ratio between credit in debt and total credit\n",
    "* ratio between credit limit and total credit\n",
    "* ratio between credit overdue and total credit\n",
    "* difference between actual and expected accound close date\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "44434faac85ff6d691d6e4c96e2ff190a590edd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Qinghui/.local/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREDIT_ACTIVE 4 ['Closed' 'Active' 'Sold' 'Bad debt']\n",
      "CREDIT_CURRENCY 4 ['currency 1' 'currency 2' 'currency 4' 'currency 3']\n",
      "CREDIT_TYPE 15 ['Consumer credit' 'Credit card' 'Mortgage' 'Car loan' 'Microloan'\n",
      " 'Loan for working capital replenishment' 'Loan for business development'\n",
      " 'Real estate loan' 'Unknown type of loan' 'Another type of loan'\n",
      " 'Cash loan (non-earmarked)' 'Loan for the purchase of equipment'\n",
      " 'Mobile operator loan' 'Interbank credit'\n",
      " 'Loan for purchase of shares (margin lending)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th>CREDIT_ACTIVE</th>\n",
       "      <th>CREDIT_CURRENCY</th>\n",
       "      <th>DAYS_CREDIT</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <th>DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>DAYS_ENDDATE_FACT</th>\n",
       "      <th>AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_CREDIT_SUM_LIMIT</th>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>CREDIT_TYPE</th>\n",
       "      <th>DAYS_CREDIT_UPDATE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_DEBT_RATIO</th>\n",
       "      <th>AMT_LIMIT_RATIO</th>\n",
       "      <th>AMT_SUM_OVERDUE_RATIO</th>\n",
       "      <th>AMT_MAX_OVERDUE_RATIO</th>\n",
       "      <th>DAYS_END_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-497</td>\n",
       "      <td>0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714463</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-208</td>\n",
       "      <td>0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-203</td>\n",
       "      <td>0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714465</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714466</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-629</td>\n",
       "      <td>0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77674.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  SK_ID_BUREAU  CREDIT_ACTIVE  CREDIT_CURRENCY  DAYS_CREDIT  \\\n",
       "0      215354       5714462              0                0         -497   \n",
       "1      215354       5714463              1                0         -208   \n",
       "2      215354       5714464              1                0         -203   \n",
       "3      215354       5714465              1                0         -203   \n",
       "4      215354       5714466              1                0         -629   \n",
       "\n",
       "   CREDIT_DAY_OVERDUE  DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  \\\n",
       "0                   0               -153.0             -153.0   \n",
       "1                   0               1075.0                NaN   \n",
       "2                   0                528.0                NaN   \n",
       "3                   0                  NaN                NaN   \n",
       "4                   0               1197.0                NaN   \n",
       "\n",
       "   AMT_CREDIT_MAX_OVERDUE  CNT_CREDIT_PROLONG      ...        \\\n",
       "0                     NaN                   0      ...         \n",
       "1                     NaN                   0      ...         \n",
       "2                     NaN                   0      ...         \n",
       "3                     NaN                   0      ...         \n",
       "4                 77674.5                   0      ...         \n",
       "\n",
       "   AMT_CREDIT_SUM_LIMIT  AMT_CREDIT_SUM_OVERDUE  CREDIT_TYPE  \\\n",
       "0                   NaN                     0.0            0   \n",
       "1                   NaN                     0.0            1   \n",
       "2                   NaN                     0.0            0   \n",
       "3                   NaN                     0.0            1   \n",
       "4                   NaN                     0.0            0   \n",
       "\n",
       "   DAYS_CREDIT_UPDATE  AMT_ANNUITY  AMT_DEBT_RATIO  AMT_LIMIT_RATIO  \\\n",
       "0              -131.0          NaN        0.000000              NaN   \n",
       "1               -20.0          NaN        0.761517              NaN   \n",
       "2               -16.0          NaN             NaN              NaN   \n",
       "3               -16.0          NaN             NaN              NaN   \n",
       "4               -21.0          NaN             NaN              NaN   \n",
       "\n",
       "   AMT_SUM_OVERDUE_RATIO  AMT_MAX_OVERDUE_RATIO  DAYS_END_DIFF  \n",
       "0                    0.0                    NaN            0.0  \n",
       "1                    0.0                    NaN            NaN  \n",
       "2                    0.0                    NaN            NaN  \n",
       "3                    0.0                    NaN            NaN  \n",
       "4                    0.0               0.028768            NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buro = pd.read_csv('../input/bureau.csv.zip')\n",
    "\n",
    "buro['DAYS_CREDIT_ENDDATE'].loc[buro['DAYS_CREDIT_ENDDATE'] < -40000] = np.nan\n",
    "buro['DAYS_CREDIT_UPDATE'].loc[buro['DAYS_CREDIT_UPDATE'] < -40000] = np.nan\n",
    "buro['DAYS_ENDDATE_FACT'].loc[buro['DAYS_ENDDATE_FACT'] < -40000] = np.nan\n",
    "\n",
    "buro['AMT_DEBT_RATIO'] = buro['AMT_CREDIT_SUM_DEBT']/(1+buro['AMT_CREDIT_SUM'])\n",
    "buro['AMT_LIMIT_RATIO'] = buro['AMT_CREDIT_SUM_LIMIT']/(1+buro['AMT_CREDIT_SUM'])\n",
    "buro['AMT_SUM_OVERDUE_RATIO'] = buro['AMT_CREDIT_SUM_OVERDUE']/(1+buro['AMT_CREDIT_SUM'])\n",
    "buro['AMT_MAX_OVERDUE_RATIO'] = buro['AMT_CREDIT_MAX_OVERDUE']/(1+buro['AMT_CREDIT_SUM'])\n",
    "buro['DAYS_END_DIFF'] = buro['DAYS_ENDDATE_FACT'] - buro['DAYS_CREDIT_ENDDATE']\n",
    "\n",
    "#Label Encoding\n",
    "categorical_feats = [\n",
    "    f for f in buro.columns if buro[f].dtype == 'object'\n",
    "]\n",
    "\n",
    "for f_ in categorical_feats:\n",
    "    nunique = buro[f_].nunique(dropna=False)\n",
    "    print(f_,nunique,buro[f_].unique())\n",
    "    buro[f_], indexer = pd.factorize(buro[f_])\n",
    "    \n",
    "buro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggragate the balance info for each buro record. Features include:\n",
    "* month account closed relative to current application\n",
    "* month with days past due (DPD) relative to current application\n",
    "* mean/sum/max DPD of each bureau account\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4f531fcbea28a0f1f4232f7f4f2fbfd3e441edf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_BUREAU\n",
      "5001718    -8\n",
      "5001720     0\n",
      "5001722   -41\n",
      "5001757    -3\n",
      "5001786   -38\n",
      "Name: MONTH_LAST_DPD, dtype: int64\n",
      "SK_ID_BUREAU\n",
      "5001709   -85\n",
      "5001710   -47\n",
      "5001712    -8\n",
      "5001716   -38\n",
      "5001717    -4\n",
      "Name: MONTH_LAST_C, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Qinghui/.local/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance_STATUS_DPD_MAX</th>\n",
       "      <th>balance_STATUS_DPD_MEAN</th>\n",
       "      <th>balance_STATUS_DPD_SUM</th>\n",
       "      <th>balance_STATUS_DPD_SCALE_SUM</th>\n",
       "      <th>balance_STATUS_DPD_SCALE_MEAN</th>\n",
       "      <th>balance_tot_STATUS_C_SUM</th>\n",
       "      <th>balance_tot_STATUS_X_SUM</th>\n",
       "      <th>balance_tot_STATUS_0_SUM</th>\n",
       "      <th>balance_tot_STATUS_DPD_SUM</th>\n",
       "      <th>balance_tot_STATUS_DPD_RATIO</th>\n",
       "      <th>balance_12_STATUS_C_SUM</th>\n",
       "      <th>balance_12_STATUS_X_SUM</th>\n",
       "      <th>balance_12_STATUS_0_SUM</th>\n",
       "      <th>balance_12_STATUS_DPD_SUM</th>\n",
       "      <th>balance_12_STATUS_DPD_RATIO</th>\n",
       "      <th>balance_has_DPD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5001709</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001710</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001711</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001712</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001713</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              balance_STATUS_DPD_MAX  balance_STATUS_DPD_MEAN  \\\n",
       "SK_ID_BUREAU                                                    \n",
       "5001709                          NaN                      NaN   \n",
       "5001710                          0.0                      0.0   \n",
       "5001711                          0.0                      0.0   \n",
       "5001712                          0.0                      0.0   \n",
       "5001713                          NaN                      NaN   \n",
       "\n",
       "              balance_STATUS_DPD_SUM  balance_STATUS_DPD_SCALE_SUM  \\\n",
       "SK_ID_BUREAU                                                         \n",
       "5001709                          0.0                           0.0   \n",
       "5001710                          0.0                           0.0   \n",
       "5001711                          0.0                           0.0   \n",
       "5001712                          0.0                           0.0   \n",
       "5001713                          0.0                           0.0   \n",
       "\n",
       "              balance_STATUS_DPD_SCALE_MEAN  balance_tot_STATUS_C_SUM  \\\n",
       "SK_ID_BUREAU                                                            \n",
       "5001709                                 0.0                        86   \n",
       "5001710                                 0.0                        48   \n",
       "5001711                                 0.0                         0   \n",
       "5001712                                 0.0                         9   \n",
       "5001713                                 0.0                         0   \n",
       "\n",
       "              balance_tot_STATUS_X_SUM  balance_tot_STATUS_0_SUM  \\\n",
       "SK_ID_BUREAU                                                       \n",
       "5001709                             11                         0   \n",
       "5001710                             30                         5   \n",
       "5001711                              1                         3   \n",
       "5001712                              0                        10   \n",
       "5001713                             22                         0   \n",
       "\n",
       "              balance_tot_STATUS_DPD_SUM  balance_tot_STATUS_DPD_RATIO  \\\n",
       "SK_ID_BUREAU                                                             \n",
       "5001709                                0                           0.0   \n",
       "5001710                                0                           0.0   \n",
       "5001711                                0                           0.0   \n",
       "5001712                                0                           0.0   \n",
       "5001713                                0                           0.0   \n",
       "\n",
       "              balance_12_STATUS_C_SUM  balance_12_STATUS_X_SUM  \\\n",
       "SK_ID_BUREAU                                                     \n",
       "5001709                          13.0                      0.0   \n",
       "5001710                          13.0                      0.0   \n",
       "5001711                           0.0                      1.0   \n",
       "5001712                           9.0                      0.0   \n",
       "5001713                           0.0                     13.0   \n",
       "\n",
       "              balance_12_STATUS_0_SUM  balance_12_STATUS_DPD_SUM  \\\n",
       "SK_ID_BUREAU                                                       \n",
       "5001709                           0.0                        0.0   \n",
       "5001710                           0.0                        0.0   \n",
       "5001711                           3.0                        0.0   \n",
       "5001712                           4.0                        0.0   \n",
       "5001713                           0.0                        0.0   \n",
       "\n",
       "              balance_12_STATUS_DPD_RATIO  balance_has_DPD  \n",
       "SK_ID_BUREAU                                                \n",
       "5001709                               0.0                0  \n",
       "5001710                               0.0                0  \n",
       "5001711                               0.0                0  \n",
       "5001712                               0.0                0  \n",
       "5001713                               0.0                0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bubl = pd.read_csv('../input/bureau_balance.csv.zip')\n",
    "#what is the last month with DPD\n",
    "bubl_last_DPD = bubl[bubl.STATUS.isin(['1','2','3','4','5'])].groupby(['SK_ID_BUREAU'])['MONTHS_BALANCE'].max()\n",
    "bubl_last_DPD.rename('MONTH_LAST_DPD', inplace=True)\n",
    "#print(bubl_last_DPD.head())\n",
    "\n",
    "#what is the last month complete\n",
    "bubl_last_C = bubl[bubl.STATUS=='C'].groupby(['SK_ID_BUREAU'])['MONTHS_BALANCE'].min()\n",
    "bubl_last_C.rename('MONTH_LAST_C',inplace=True)\n",
    "#print(bubl_last_C.head())\n",
    "\n",
    "bubl['STATUS_DPD'] = bubl['STATUS']\n",
    "bubl['STATUS_DPD'].loc[bubl['STATUS_DPD'].isin(['C','X'])]=np.nan\n",
    "bubl['STATUS_DPD'] = bubl['STATUS_DPD'].astype('float')\n",
    "bubl['YEAR_SCALE'] = (bubl['MONTHS_BALANCE']/12.0).apply(np.exp)\n",
    "bubl['STATUS_DPD_SCALE'] = bubl['STATUS_DPD'] * bubl['YEAR_SCALE']\n",
    "num_aggregations = {\n",
    "    'STATUS_DPD': [ 'max', 'mean', 'sum'],\n",
    "    'STATUS_DPD_SCALE': [ 'sum',],\n",
    "    'YEAR_SCALE': [ 'sum']\n",
    "}\n",
    "balance = bubl.groupby('SK_ID_BUREAU').agg(num_aggregations)\n",
    "balance.columns = pd.Index(['balance_' + e[0] + \"_\" + e[1].upper() for e in balance.columns.tolist()])\n",
    "balance['balance_STATUS_DPD_SCALE_MEAN'] = balance['balance_STATUS_DPD_SCALE_SUM']/balance['balance_YEAR_SCALE_SUM']\n",
    "del balance['balance_YEAR_SCALE_SUM']\n",
    "gc.collect()\n",
    "bubl_STATUS = pd.concat([bubl[['SK_ID_BUREAU','MONTHS_BALANCE']], pd.get_dummies(bubl['STATUS'], prefix='STATUS')], axis=1)\n",
    "bubl_STATUS['STATUS_DPD'] = bubl_STATUS['STATUS_1'] + bubl_STATUS['STATUS_2'] + bubl_STATUS['STATUS_3'] + bubl_STATUS['STATUS_4'] + bubl_STATUS['STATUS_5'] \n",
    "num_aggregations = {\n",
    "    'STATUS_C': [ 'sum'],\n",
    "    'STATUS_X': [ 'sum'],\n",
    "    'STATUS_0': [ 'sum'],\n",
    "    'STATUS_DPD': ['sum']\n",
    "}\n",
    "balance_tot =  bubl_STATUS.groupby('SK_ID_BUREAU').agg(num_aggregations)\n",
    "balance_12 =  bubl_STATUS.loc[bubl_STATUS['MONTHS_BALANCE']>=-12].groupby('SK_ID_BUREAU').agg(num_aggregations)\n",
    "balance_tot.columns = pd.Index(['balance_tot_' + e[0] + \"_\" + e[1].upper() for e in balance_tot.columns.tolist()])\n",
    "balance_12.columns = pd.Index(['balance_12_' + e[0] + \"_\" + e[1].upper() for e in balance_12.columns.tolist()])\n",
    "balance_tot['balance_tot_STATUS_DPD_RATIO'] = balance_tot['balance_tot_STATUS_DPD_SUM']/(0.001 + balance_tot['balance_tot_STATUS_0_SUM'] + balance_tot['balance_tot_STATUS_DPD_SUM'])\n",
    "balance_12['balance_12_STATUS_DPD_RATIO'] = balance_12['balance_12_STATUS_DPD_SUM']/(0.001 + balance_12['balance_12_STATUS_0_SUM'] + balance_12['balance_12_STATUS_DPD_SUM'])\n",
    "balance = balance.merge(balance_tot, how='outer', on='SK_ID_BUREAU')             \n",
    "balance = balance.merge(balance_12, how='outer', on='SK_ID_BUREAU')\n",
    "balance['balance_has_DPD'] = (balance['balance_STATUS_DPD_MAX']>0).astype('int')\n",
    "\n",
    "del balance_tot, balance_12, bubl_STATUS\n",
    "gc.collect()\n",
    "balance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge bureau balance feature with main bureau table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "baa65f969f4705f92b5d144b24e6e5bc4aff9cc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716428, 38)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buro_meta = buro.merge(balance, on='SK_ID_BUREAU', how='left')\n",
    "del buro, balance\n",
    "gc.collect()\n",
    "print(\"bureau data shape\", buro_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "broadcast current target to bureau record, according to the current ID each bureau record correspond to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7d109c5151936146a9c725c25d69261d1410f75e"
   },
   "outputs": [],
   "source": [
    "target_map = pd.Series(data.TARGET.values, index=data.SK_ID_CURR.values)\n",
    "y = buro_meta['SK_ID_CURR'].map(target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test set (test set are those without target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "404c1dac11574526686d7600d65068d26da7ce52"
   },
   "outputs": [],
   "source": [
    "train_x = buro_meta.loc[~y.isnull()]\n",
    "test_x = buro_meta.loc[y.isnull()]\n",
    "train_y = y.loc[~y.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "43bfc82ca17e3f3fe79c683d8ba36d07497c1a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK_ID_CURR', 'SK_ID_BUREAU']\n"
     ]
    }
   ],
   "source": [
    "excluded_feats = ['SK_ID_CURR','SK_ID_BUREAU']\n",
    "features = [f_ for f_ in train_x.columns.values if not f_ in excluded_feats]\n",
    "print(excluded_feats)\n",
    "\n",
    "train_x = buro_meta.loc[~y.isnull()]\n",
    "test_x = buro_meta.loc[y.isnull()]\n",
    "train_y = y.loc[~y.isnull()]\n",
    "\n",
    "# Run a 5 fold\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "oof_preds = np.zeros(train_x.shape[0])\n",
    "sub_preds = np.zeros(test_x.shape[0])\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train LightGBM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "3b177a74c9d45c1c8fb9f64e2dd4651cc948dced"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Qinghui/.local/lib/python3.6/site-packages/lightgbm/basic.py:1161: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 60 rounds.\n",
      "[100]\tvalid_0's auc: 0.612689\n",
      "[200]\tvalid_0's auc: 0.616326\n",
      "[300]\tvalid_0's auc: 0.618119\n",
      "[400]\tvalid_0's auc: 0.619222\n",
      "[500]\tvalid_0's auc: 0.619848\n",
      "[600]\tvalid_0's auc: 0.620398\n",
      "[700]\tvalid_0's auc: 0.62081\n",
      "[800]\tvalid_0's auc: 0.621138\n",
      "[900]\tvalid_0's auc: 0.621482\n",
      "[1000]\tvalid_0's auc: 0.621704\n",
      "[1100]\tvalid_0's auc: 0.622079\n",
      "[1200]\tvalid_0's auc: 0.622226\n",
      "Early stopping, best iteration is:\n",
      "[1222]\tvalid_0's auc: 0.622263\n",
      "Fold  1 AUC : 0.622263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Qinghui/.local/lib/python3.6/site-packages/lightgbm/basic.py:1161: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 60 rounds.\n",
      "[100]\tvalid_0's auc: 0.608626\n",
      "[200]\tvalid_0's auc: 0.611405\n",
      "[300]\tvalid_0's auc: 0.613098\n",
      "[400]\tvalid_0's auc: 0.614506\n",
      "[500]\tvalid_0's auc: 0.615284\n",
      "[600]\tvalid_0's auc: 0.615794\n",
      "[700]\tvalid_0's auc: 0.616296\n",
      "[800]\tvalid_0's auc: 0.616477\n",
      "[900]\tvalid_0's auc: 0.616608\n",
      "Early stopping, best iteration is:\n",
      "[920]\tvalid_0's auc: 0.616638\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-36c99064f3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0moof_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0msub_preds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mfold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \"\"\"\n\u001b[1;32m    779\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[0;32m--> 780\u001b[0;31m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m    560\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m--> 561\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, pred_parameter, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_has_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_x, train_y)):\n",
    "    trn_x, val_x = train_x[features].iloc[trn_idx], train_x[features].iloc[val_idx]\n",
    "    trn_y, val_y = train_y.iloc[trn_idx], train_y.iloc[val_idx]\n",
    "    \n",
    "    clf = LGBMClassifier(\n",
    "        n_estimators=5000,\n",
    "        learning_rate=0.05,\n",
    "        metric = 'auc',\n",
    "        num_leaves=20,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.9,\n",
    "        max_depth=5,\n",
    "        reg_alpha=5,\n",
    "        reg_lambda=4,\n",
    "        min_split_gain=0.002,\n",
    "        min_child_weight=40,\n",
    "        silent=True,\n",
    "        verbose=-1,\n",
    "        n_jobs = 16,\n",
    "        random_state = n_fold * 619,\n",
    "        scale_pos_weight = 2\n",
    "    )\n",
    "    \n",
    "    clf.fit(trn_x, trn_y, \n",
    "            eval_set= [(val_x, val_y)], \n",
    "            eval_metric='auc', verbose=100, early_stopping_rounds=60,\n",
    "            categorical_feature = categorical_feats,\n",
    "           )\n",
    "    \n",
    "    oof_preds[val_idx] = clf.predict_proba(val_x)[:, 1]\n",
    "    sub_preds += clf.predict_proba(test_x[features])[:, 1] / folds.n_splits\n",
    "    \n",
    "    fold_score = roc_auc_score(val_y, oof_preds[val_idx])\n",
    "    scores.append(fold_score)\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, fold_score))\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    del clf, trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "print('Full AUC score %.6f +- %0.4f' % (roc_auc_score(train_y, oof_preds), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get prediction for each bureau record -- giving each bureau record a score, which meatures how likely it belongs to a user who has defaulting account currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15ca65952b8a26f0ef3f277097b41a4a8910cb26",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_buro_score = train_x[['SK_ID_CURR','SK_ID_BUREAU','DAYS_CREDIT']]\n",
    "train_buro_score['score'] = oof_preds\n",
    "test_buro_score = test_x[['SK_ID_CURR','SK_ID_BUREAU','DAYS_CREDIT']]\n",
    "test_buro_score['score'] = sub_preds\n",
    "buro_score = pd.concat([train_buro_score,test_buro_score])\n",
    "buro_score.to_csv('../output/buro_score.csv',index=False,compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group by current ID, create aggragated bureau score. These will be the features we use for final training.\n",
    "\n",
    "aggragated features include: mean, max, sum, variance, sum of past two year.\n",
    "\n",
    "Note we subtract the global mean of all predictions, this is to prevent the \"sum\" feature penalized users with more accounts. The max/mean/var features are not affected by the substraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da2e2d5b227be80c2d6fd3c0c8ac85c9a7bd5dd7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buro_score['score'] -= buro_score['score'].mean()\n",
    "agg_buro_score = buro_score.groupby('SK_ID_CURR')['score'].agg({'max','mean','sum','var'})\n",
    "\n",
    "agg_buro_score_recent2y = buro_score.loc[buro_score['DAYS_CREDIT']>-365.25*2].groupby('SK_ID_CURR')['score'].sum()\n",
    "\n",
    "idx = buro_score.groupby(['SK_ID_CURR'])['DAYS_CREDIT'].idxmax()\n",
    "agg_buro_score_last = buro_score[['SK_ID_CURR','score']].loc[idx.values]\n",
    "agg_buro_score_last.set_index('SK_ID_CURR',inplace=True)\n",
    "\n",
    "agg_buro_score['recent2y_sum'] = agg_buro_score_recent2y\n",
    "agg_buro_score['last'] = agg_buro_score_last\n",
    "agg_buro_score = agg_buro_score.add_prefix('buro_score_')\n",
    "agg_buro_score['TARGET'] = target_map\n",
    "agg_buro_score.to_csv('../output/agg_buro_score.csv',compression='zip')\n",
    "agg_buro_score.groupby('TARGET').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how the aggregated features are correlated to current target. Idealy we should see a significant correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ccba4ff2a8dddf4f4197cc3ad5fbae224c1057b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in agg_buro_score.columns:\n",
    "    print(col,agg_buro_score[col].corr(agg_buro_score['TARGET']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a0c8db4add26ef2277a506ade230c90d646dc38",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "feature_importance = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "    by=\"importance\", ascending=False)\n",
    "#feature_importance['correlation'] = corr.loc[feature_importance.index.values]\n",
    "feature_importance.to_csv('../output/prev_training_feature_importance.csv')\n",
    "\n",
    "best_features = feature_importance.iloc[:50].reset_index()\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "fig = plt.figure(figsize=(8, 16))\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "# Plot Split importances\n",
    "ax = plt.subplot(gs[0, 0])\n",
    "sns.barplot(x='importance', y='feature', data=best_features, ax=ax)\n",
    "ax.set_title('Feature scores wrt split importances', fontweight='bold', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
